# A Probabilistic Perspective on Unlearning and Alignment for Large Language Models

<img src="./logo.png">

Reference implementation of the probabilistic evaluation framework proposed in the paper:

**<a href='https://openreview.net/pdf?id=51WraMid8K'>A Probabilistic Perspective on Unlearning and Alignment for Large Language Models</a>**<br>
*Yan Scholten, Stephan Günnemann, Leo Schwinn*<br>
International Conference on Learning Representations, ICLR 2025 (Oral)<br>
[ <a href='https://www.cs.cit.tum.de/daml/probabilistic-unlearning/'>Project page</a> | <a href='https://openreview.net/pdf?id=51WraMid8K'>PDF</a> ]

## Code Coming Soon

Training code and more supplementary materials will be released soon. In the meantime, you can explore our [demo notebook](sampling-demo.ipynb), which demonstrates that greedy evaluations can misleadingly suggest successful unlearning, while our probabilistic evaluations provide more accurate assessments of model capabilities.

## Cite
Please cite our paper if you use this code in your own work:

```
@inproceedings{scholten2024probabilistic,
    title={A Probabilistic Perspective on Unlearning and Alignment for Large Language Models},
    author={Yan Scholten and Stephan G{\"u}nnemann and Leo Schwinn},
    booktitle={The Thirteenth International Conference on Learning Representations},
    year={2025},
    url={https://openreview.net/forum?id=51WraMid8K}
}
```

## Contact

For questions and feedback please contact:

Yan Scholten, Technical University of Munich<br>
Stephan Günnemann, Technical University of Munich<br>
Leo Schwinn, Technical University of Munich

## License

The code by Yan Scholten, Stephan Günnemann and Leo Schwinn is licensed under MIT license.
